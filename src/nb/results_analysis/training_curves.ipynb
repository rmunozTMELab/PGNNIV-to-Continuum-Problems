{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "custom_seed = 42\n",
    "np.random.seed(custom_seed)\n",
    "tf.random.set_seed(custom_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar datos y resultados\n",
    "def cargar_datos_y_resultados(model_name):\n",
    "    data_folder = r' '\n",
    "    name_data_archive = f'{model_name}_data.pkl'\n",
    "    pickle_archive = os.path.join(data_folder, name_data_archive)\n",
    "\n",
    "    with open(pickle_archive, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    # Load first training\n",
    "    results_folder = r' '\n",
    "    archive_name_first_train = f'{model_name}_results\\{model_name}_first_train.pkl'\n",
    "    pickle_archive = os.path.join(results_folder, archive_name_first_train)\n",
    "\n",
    "    with open(pickle_archive, 'rb') as f:\n",
    "        results_first_train_pkl = pickle.load(f)\n",
    "\n",
    "    results_first_train = results_first_train_pkl['training']\n",
    "    predictions_predictive_first_train = results_first_train_pkl['predictions_pred']\n",
    "    predictions_explanatory_first_train = results_first_train_pkl['predictions_exp']\n",
    "\n",
    "    # Load new training\n",
    "    archive_name_new_train = f'{model_name}_results\\{model_name}_new_train.pkl'\n",
    "    pickle_archive = os.path.join(results_folder, archive_name_new_train)\n",
    "\n",
    "    with open(pickle_archive, 'rb') as f:\n",
    "        results_new_train_pkl = pickle.load(f)\n",
    "\n",
    "    results_new_train = results_new_train_pkl['training']\n",
    "    predictions_predictive_new_train = results_new_train_pkl['predictions_pred']\n",
    "    predictions_explanatory_new_train = results_new_train_pkl['predictions_exp']\n",
    "\n",
    "    return data, results_first_train, predictions_predictive_first_train, predictions_explanatory_first_train, results_new_train, predictions_predictive_new_train, predictions_explanatory_new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model \"heterogeneous_problem\"\n",
    "data_heterogeneous_problem, results_first_train_heterogeneous_problem, predictions_predictive_first_train_heterogeneous_problem, predictions_explanatory_first_train_heterogeneous_problem, results_new_train_heterogeneous_problem, predictions_predictive_new_train_heterogeneous_problem, predictions_explanatory_new_train_heterogeneous_problem = cargar_datos_y_resultados(\"heterogeneous_problem\")\n",
    "\n",
    "# Model \"tensorial_problem\"\n",
    "data_tensorial_problem, results_first_train_tensorial_problem, predictions_predictive_first_train_tensorial_problem, predictions_explanatory_first_train_tensorial_problem, results_new_train_tensorial_problem, predictions_predictive_new_train_tensorial_problem, predictions_explanatory_new_train_tensorial_problem = cargar_datos_y_resultados(\"tensorial_problem\")\n",
    "\n",
    "# Model \"nonlinear_problem_P3\"\n",
    "data_nonlinear_problem_P3, results_first_train_nonlinear_problem_P3, predictions_predictive_first_train_nonlinear_problem_P3, predictions_explanatory_first_train_nonlinear_problem_P3, results_new_train_nonlinear_problem_P3, predictions_predictive_new_train_nonlinear_problem_P3, predictions_explanatory_new_train_nonlinear_problem_P3 = cargar_datos_y_resultados(\"nonlinear_problem_P3\")\n",
    "\n",
    "# Model \"nonlinear_problem_P4\"\n",
    "data_nonlinear_problem_P4, results_first_train_nonlinear_problem_P4, predictions_predictive_first_train_nonlinear_problem_P4, predictions_explanatory_first_train_nonlinear_problem_P4, results_new_train_nonlinear_problem_P4, predictions_predictive_new_train_nonlinear_problem_P4, predictions_explanatory_new_train_nonlinear_problem_P4 = cargar_datos_y_resultados(\"nonlinear_problem_P4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = data_nonlinear_problem_P4['n_data']\n",
    "n_discretization = data_nonlinear_problem_P4['n_discretization']\n",
    "x_step_size = data_nonlinear_problem_P4['x_step_size']\n",
    "y_step_size = data_nonlinear_problem_P4['y_step_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finite difference convolutional operator to derivate in x axis\n",
    "def Dx(f, x_step_size=x_step_size):\n",
    "    Dx = tf.constant([[-1, +1], \n",
    "                      [-1, +1]], \n",
    "                     dtype=tf.float32)/(2*x_step_size)\n",
    "\n",
    "    f_reshaped = tf.expand_dims(f[:, :, :], axis=-1)    \n",
    "    Dx = tf.expand_dims(tf.expand_dims(Dx, axis=-1), axis=-1)\n",
    "    dfdx = tf.nn.conv2d(f_reshaped, Dx, strides=[1, 1, 1, 1], padding='VALID', name='dfdx')\n",
    "    return tf.squeeze(dfdx, axis=-1)\n",
    "\n",
    "# Finite difference convolutional operator to derivate in y axis\n",
    "def Dy(f, y_step_size=y_step_size):\n",
    "    Dy = tf.constant([[+1, +1], \n",
    "                      [-1, -1]],  \n",
    "                     dtype=tf.float32)/(-2*y_step_size)\n",
    "\n",
    "    f_reshaped = tf.expand_dims(f[:, :, :], axis=-1)    \n",
    "    Dy = tf.expand_dims(tf.expand_dims(Dy, axis=-1), axis=-1)\n",
    "    dfdy = tf.nn.conv2d(f_reshaped, Dy, strides=[1, 1, 1, 1], padding='VALID', name='dfdy')\n",
    "    return tf.squeeze(dfdy, axis=-1)\n",
    "\n",
    "# Convolutional operator to do the mean between two elements of a mesh in x axis\n",
    "def Mx(f):\n",
    "    Mx = tf.constant([[+1, +1]], \n",
    "                     dtype=tf.float32)/(2)\n",
    "\n",
    "    f_reshaped = tf.expand_dims(f[:, :, :], axis=-1)    \n",
    "    Mx = tf.expand_dims(tf.expand_dims(Mx, axis=-1), axis=-1)\n",
    "    x_avg = tf.nn.conv2d(f_reshaped, Mx, strides=[1, 1, 1, 1], padding='VALID', name='Mx')\n",
    "    return tf.squeeze(x_avg, axis=-1)\n",
    "\n",
    "# Convolutional operator to do the mean between two elements of a mesh in y axis\n",
    "def My(f):\n",
    "    My = tf.constant([[+1], \n",
    "                      [+1]], \n",
    "                     dtype=tf.float32)/(2)\n",
    "\n",
    "    f_reshaped = tf.expand_dims(f[:, :, :], axis=-1)    \n",
    "    My = tf.expand_dims(tf.expand_dims(My, axis=-1), axis=-1)\n",
    "    y_avg = tf.nn.conv2d(f_reshaped, My, strides=[1, 1, 1, 1], padding='VALID', name='My')\n",
    "    return tf.squeeze(y_avg, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(data, window_size=50):\n",
    "    window = np.ones(window_size) / window_size\n",
    "    return np.convolve(data, window, mode='valid')\n",
    "\n",
    "def cm_to_in(cm):\n",
    "    return cm * 0.393701\n",
    "\n",
    "def normalize_list(lst):\n",
    "    max_value = max(lst)\n",
    "    return [x / max_value for x in lst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parámetros de las gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "linewidth = 1.5  \n",
    "title_fontsize = 14  \n",
    "label_fontsize = 14  \n",
    "legend_fontsize = 12 \n",
    "tick_fontsize = 11  \n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "posX = cm_to_in(10) # posición de la esquina inferior izquierda de la imagen en X\n",
    "posY = cm_to_in(10) # posición de la esquina inferior izquierda de la imagen en Y\n",
    "width = cm_to_in(12)  # ancho de la imagen\n",
    "height = cm_to_in(8) # alto de la imagen\n",
    "\n",
    "color = [0.1, 0, 0.8]  # triplete RGB, valores entre 0 y 1\n",
    "subplot_adjust_left = cm_to_in(0.15)\n",
    "subplot_adjust_bottom = cm_to_in(0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves of heterogeneous problem\n",
    "train_total_loss_list_heterogeneous_problem = results_first_train_heterogeneous_problem['train_total_loss_list'] + results_new_train_heterogeneous_problem['train_total_loss_list']\n",
    "test_total_loss_list_heterogeneous_problem = results_first_train_heterogeneous_problem['test_total_loss_list'] + results_new_train_heterogeneous_problem['test_total_loss_list']\n",
    "train_total_MSE_list_heterogeneous_problem = results_first_train_heterogeneous_problem['train_total_MSE_list'] + results_new_train_heterogeneous_problem['train_total_MSE_list']\n",
    "test_total_MSE_list_heterogeneous_problem = results_first_train_heterogeneous_problem['test_total_MSE_list'] + results_new_train_heterogeneous_problem['test_total_MSE_list']\n",
    "\n",
    "# Training curves of tensorial problem\n",
    "data_tensorial_problem, results_first_train_tensorial_problem, predictions_predictive_first_train_tensorial_problem, predictions_explanatory_first_train_tensorial_problem, results_new_train_tensorial_problem, predictions_predictive_new_train_tensorial_problem, predictions_explanatory_new_train_tensorial_problem = cargar_datos_y_resultados(\"tensorial_problem\")\n",
    "train_total_loss_list_tensorial_problem = results_first_train_tensorial_problem['train_total_loss_list'] + results_new_train_tensorial_problem['train_total_loss_list']\n",
    "test_total_loss_list_tensorial_problem = results_first_train_tensorial_problem['test_total_loss_list'] + results_new_train_tensorial_problem['test_total_loss_list']\n",
    "train_total_MSE_list_tensorial_problem = results_first_train_tensorial_problem['train_total_MSE_list'] + results_new_train_tensorial_problem['train_total_MSE_list']\n",
    "test_total_MSE_list_tensorial_problem = results_first_train_tensorial_problem['test_total_MSE_list'] + results_new_train_tensorial_problem['test_total_MSE_list']\n",
    "\n",
    "# Training curves of nonlinear problem P3\n",
    "train_total_loss_list_nonlinear_problem_P3 = results_first_train_nonlinear_problem_P3['train_total_loss_list'] + results_new_train_nonlinear_problem_P3['train_total_loss_list']\n",
    "test_total_loss_list_nonlinear_problem_P3 = results_first_train_nonlinear_problem_P3['test_total_loss_list'] + results_new_train_nonlinear_problem_P3['test_total_loss_list']\n",
    "train_total_MSE_list_nonlinear_problem_P3 = results_first_train_nonlinear_problem_P3['train_total_MSE_list'] + results_new_train_nonlinear_problem_P3['train_total_MSE_list']\n",
    "test_total_MSE_list_nonlinear_problem_P3 = results_first_train_nonlinear_problem_P3['test_total_MSE_list'] + results_new_train_nonlinear_problem_P3['test_total_MSE_list']\n",
    "\n",
    "# Training curves of nonlinear problem P4\n",
    "train_total_loss_list_nonlinear_problem_P4 = results_first_train_nonlinear_problem_P4['train_total_loss_list'] + results_new_train_nonlinear_problem_P4['train_total_loss_list']\n",
    "test_total_loss_list_nonlinear_problem_P4 = results_first_train_nonlinear_problem_P4['test_total_loss_list'] + results_new_train_nonlinear_problem_P4['test_total_loss_list']\n",
    "train_total_MSE_list_nonlinear_problem_P4 = results_first_train_nonlinear_problem_P4['train_total_MSE_list'] + results_new_train_nonlinear_problem_P4['train_total_MSE_list']\n",
    "test_total_MSE_list_nonlinear_problem_P4 = results_first_train_nonlinear_problem_P4['test_total_MSE_list'] + results_new_train_nonlinear_problem_P4['test_total_MSE_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step will be done if data haven't been normalized when results are beeing saved after each training iteration\n",
    "N_batch = 64\n",
    "\n",
    "train_total_loss_list_heterogeneous_problem = [x / N_batch for x in train_total_loss_list_heterogeneous_problem]\n",
    "train_total_loss_list_tensorial_problem = [x / N_batch for x in train_total_loss_list_tensorial_problem]\n",
    "train_total_loss_list_nonlinear_problem_P3 = [x / N_batch for x in train_total_loss_list_nonlinear_problem_P3]\n",
    "train_total_loss_list_nonlinear_problem_P4 = [x / N_batch for x in train_total_loss_list_nonlinear_problem_P4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "plt.plot(smooth_curve(train_total_loss_list_heterogeneous_problem), label='H', color='blue', linestyle='-')\n",
    "plt.plot(smooth_curve(train_total_loss_list_tensorial_problem), label='A', color='red', linestyle='-')\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=label_fontsize)\n",
    "plt.ylabel('Loss', fontsize=label_fontsize)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend(loc='lower left', fontsize=legend_fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlim(left=1) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "plt.plot(smooth_curve(train_total_loss_list_nonlinear_problem_P3), label='NL1', color='black', linestyle='-')\n",
    "plt.plot(smooth_curve(train_total_loss_list_nonlinear_problem_P4), label='NL2', color='green', linestyle='-')\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=label_fontsize)\n",
    "plt.ylabel('Loss', fontsize=label_fontsize)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend(loc='lower left', fontsize=legend_fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlim(left=1) \n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tests_enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
