{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "custom_seed = 42\n",
    "np.random.seed(custom_seed)\n",
    "tf.random.set_seed(custom_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar datos y resultados\n",
    "def cargar_datos_y_resultados(model_name):\n",
    "    data_folder = r\"/home/rmunoz/Escritorio/rmunozTMELab/PGNNIV-to-Continuum-Problems/data\"\n",
    "    name_data_archive = f'{model_name}_data.pkl'\n",
    "    pickle_archive = os.path.join(data_folder, name_data_archive)\n",
    "\n",
    "    with open(pickle_archive, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    # Load first training\n",
    "    results_folder = r\"/home/rmunoz/Escritorio/rmunozTMELab/PGNNIV-to-Continuum-Problems/results\"\n",
    "    archive_name_first_train = f'{model_name}_results\\{model_name}_first_train.pkl'\n",
    "    pickle_archive = os.path.join(results_folder, archive_name_first_train)\n",
    "\n",
    "    with open(pickle_archive, 'rb') as f:\n",
    "        results_first_train_pkl = pickle.load(f)\n",
    "\n",
    "    results_first_train = results_first_train_pkl['training']\n",
    "    predictions_predictive_first_train = results_first_train_pkl['predictions_pred']\n",
    "    predictions_explanatory_first_train = results_first_train_pkl['predictions_exp']\n",
    "\n",
    "    # Load new training\n",
    "    archive_name_new_train = f'{model_name}_results\\{model_name}_new_train.pkl'\n",
    "    pickle_archive = os.path.join(results_folder, archive_name_new_train)\n",
    "\n",
    "    with open(pickle_archive, 'rb') as f:\n",
    "        results_new_train_pkl = pickle.load(f)\n",
    "\n",
    "    results_new_train = results_new_train_pkl['training']\n",
    "    predictions_predictive_new_train = results_new_train_pkl['predictions_pred']\n",
    "    predictions_explanatory_new_train = results_new_train_pkl['predictions_exp']\n",
    "\n",
    "    return data, results_first_train, predictions_predictive_first_train, predictions_explanatory_first_train, results_new_train, predictions_predictive_new_train, predictions_explanatory_new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/rmunoz/Escritorio/rmunozTMELab/PGNNIV-to-Continuum-Problems/results/heterogeneous_problem_results\\\\heterogeneous_problem_first_train.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Model \"heterogeneous_problem\"\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data_heterogeneous_problem, results_first_train_heterogeneous_problem, predictions_predictive_first_train_heterogeneous_problem, predictions_explanatory_first_train_heterogeneous_problem, results_new_train_heterogeneous_problem, predictions_predictive_new_train_heterogeneous_problem, predictions_explanatory_new_train_heterogeneous_problem \u001b[38;5;241m=\u001b[39m \u001b[43mcargar_datos_y_resultados\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheterogeneous_problem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Model \"tensorial_problem\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m data_tensorial_problem, results_first_train_tensorial_problem, predictions_predictive_first_train_tensorial_problem, predictions_explanatory_first_train_tensorial_problem, results_new_train_tensorial_problem, predictions_predictive_new_train_tensorial_problem, predictions_explanatory_new_train_tensorial_problem \u001b[38;5;241m=\u001b[39m cargar_datos_y_resultados(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorial_problem\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[26], line 15\u001b[0m, in \u001b[0;36mcargar_datos_y_resultados\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     12\u001b[0m archive_name_first_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_results\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_first_train.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m pickle_archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(results_folder, archive_name_first_train)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpickle_archive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     16\u001b[0m     results_first_train_pkl \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     18\u001b[0m results_first_train \u001b[38;5;241m=\u001b[39m results_first_train_pkl[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/PGNNIV_continuum_paper_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/rmunoz/Escritorio/rmunozTMELab/PGNNIV-to-Continuum-Problems/results/heterogeneous_problem_results\\\\heterogeneous_problem_first_train.pkl'"
     ]
    }
   ],
   "source": [
    "# Model \"heterogeneous_problem\"\n",
    "data_heterogeneous_problem, results_first_train_heterogeneous_problem, predictions_predictive_first_train_heterogeneous_problem, predictions_explanatory_first_train_heterogeneous_problem, results_new_train_heterogeneous_problem, predictions_predictive_new_train_heterogeneous_problem, predictions_explanatory_new_train_heterogeneous_problem = cargar_datos_y_resultados(\"heterogeneous_problem\")\n",
    "\n",
    "# Model \"tensorial_problem\"\n",
    "data_tensorial_problem, results_first_train_tensorial_problem, predictions_predictive_first_train_tensorial_problem, predictions_explanatory_first_train_tensorial_problem, results_new_train_tensorial_problem, predictions_predictive_new_train_tensorial_problem, predictions_explanatory_new_train_tensorial_problem = cargar_datos_y_resultados(\"tensorial_problem\")\n",
    "\n",
    "# Model \"nonlinear_problem_P3\"\n",
    "data_nonlinear_problem_P3, results_first_train_nonlinear_problem_P3, predictions_predictive_first_train_nonlinear_problem_P3, predictions_explanatory_first_train_nonlinear_problem_P3, results_new_train_nonlinear_problem_P3, predictions_predictive_new_train_nonlinear_problem_P3, predictions_explanatory_new_train_nonlinear_problem_P3 = cargar_datos_y_resultados(\"nonlinear_problem_P3\")\n",
    "\n",
    "# Model \"nonlinear_problem_P4\"\n",
    "data_nonlinear_problem_P4, results_first_train_nonlinear_problem_P4, predictions_predictive_first_train_nonlinear_problem_P4, predictions_explanatory_first_train_nonlinear_problem_P4, results_new_train_nonlinear_problem_P4, predictions_predictive_new_train_nonlinear_problem_P4, predictions_explanatory_new_train_nonlinear_problem_P4 = cargar_datos_y_resultados(\"nonlinear_problem_P4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = data_nonlinear_problem_P4['n_data']\n",
    "n_discretization = data_nonlinear_problem_P4['n_discretization']\n",
    "x_step_size = data_nonlinear_problem_P4['x_step_size']\n",
    "y_step_size = data_nonlinear_problem_P4['y_step_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finite difference convolutional operator to derivate in x axis\n",
    "def Dx(f, x_step_size=x_step_size):\n",
    "    Dx = tf.constant([[-1, +1], \n",
    "                      [-1, +1]], \n",
    "                     dtype=tf.float32)/(2*x_step_size)\n",
    "\n",
    "    f_reshaped = tf.expand_dims(f[:, :, :], axis=-1)    \n",
    "    Dx = tf.expand_dims(tf.expand_dims(Dx, axis=-1), axis=-1)\n",
    "    dfdx = tf.nn.conv2d(f_reshaped, Dx, strides=[1, 1, 1, 1], padding='VALID', name='dfdx')\n",
    "    return tf.squeeze(dfdx, axis=-1)\n",
    "\n",
    "# Finite difference convolutional operator to derivate in y axis\n",
    "def Dy(f, y_step_size=y_step_size):\n",
    "    Dy = tf.constant([[+1, +1], \n",
    "                      [-1, -1]],  \n",
    "                     dtype=tf.float32)/(-2*y_step_size)\n",
    "\n",
    "    f_reshaped = tf.expand_dims(f[:, :, :], axis=-1)    \n",
    "    Dy = tf.expand_dims(tf.expand_dims(Dy, axis=-1), axis=-1)\n",
    "    dfdy = tf.nn.conv2d(f_reshaped, Dy, strides=[1, 1, 1, 1], padding='VALID', name='dfdy')\n",
    "    return tf.squeeze(dfdy, axis=-1)\n",
    "\n",
    "# Convolutional operator to do the mean between two elements of a mesh in x axis\n",
    "def Mx(f):\n",
    "    Mx = tf.constant([[+1, +1]], \n",
    "                     dtype=tf.float32)/(2)\n",
    "\n",
    "    f_reshaped = tf.expand_dims(f[:, :, :], axis=-1)    \n",
    "    Mx = tf.expand_dims(tf.expand_dims(Mx, axis=-1), axis=-1)\n",
    "    x_avg = tf.nn.conv2d(f_reshaped, Mx, strides=[1, 1, 1, 1], padding='VALID', name='Mx')\n",
    "    return tf.squeeze(x_avg, axis=-1)\n",
    "\n",
    "# Convolutional operator to do the mean between two elements of a mesh in y axis\n",
    "def My(f):\n",
    "    My = tf.constant([[+1], \n",
    "                      [+1]], \n",
    "                     dtype=tf.float32)/(2)\n",
    "\n",
    "    f_reshaped = tf.expand_dims(f[:, :, :], axis=-1)    \n",
    "    My = tf.expand_dims(tf.expand_dims(My, axis=-1), axis=-1)\n",
    "    y_avg = tf.nn.conv2d(f_reshaped, My, strides=[1, 1, 1, 1], padding='VALID', name='My')\n",
    "    return tf.squeeze(y_avg, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(data, window_size=50):\n",
    "    window = np.ones(window_size) / window_size\n",
    "    return np.convolve(data, window, mode='valid')\n",
    "\n",
    "def cm_to_in(cm):\n",
    "    return cm * 0.393701\n",
    "\n",
    "def normalize_list(lst):\n",
    "    max_value = max(lst)\n",
    "    return [x / max_value for x in lst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parámetros de las gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "linewidth = 1.5  \n",
    "title_fontsize = 14  \n",
    "label_fontsize = 14  \n",
    "legend_fontsize = 12 \n",
    "tick_fontsize = 11  \n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "posX = cm_to_in(10) # posición de la esquina inferior izquierda de la imagen en X\n",
    "posY = cm_to_in(10) # posición de la esquina inferior izquierda de la imagen en Y\n",
    "width = cm_to_in(12)  # ancho de la imagen\n",
    "height = cm_to_in(8) # alto de la imagen\n",
    "\n",
    "color = [0.1, 0, 0.8]  # triplete RGB, valores entre 0 y 1\n",
    "subplot_adjust_left = cm_to_in(0.15)\n",
    "subplot_adjust_bottom = cm_to_in(0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves of heterogeneous problem\n",
    "train_total_loss_list_heterogeneous_problem = results_first_train_heterogeneous_problem['train_total_loss_list'] + results_new_train_heterogeneous_problem['train_total_loss_list']\n",
    "test_total_loss_list_heterogeneous_problem = results_first_train_heterogeneous_problem['test_total_loss_list'] + results_new_train_heterogeneous_problem['test_total_loss_list']\n",
    "train_total_MSE_list_heterogeneous_problem = results_first_train_heterogeneous_problem['train_total_MSE_list'] + results_new_train_heterogeneous_problem['train_total_MSE_list']\n",
    "test_total_MSE_list_heterogeneous_problem = results_first_train_heterogeneous_problem['test_total_MSE_list'] + results_new_train_heterogeneous_problem['test_total_MSE_list']\n",
    "\n",
    "# Training curves of tensorial problem\n",
    "data_tensorial_problem, results_first_train_tensorial_problem, predictions_predictive_first_train_tensorial_problem, predictions_explanatory_first_train_tensorial_problem, results_new_train_tensorial_problem, predictions_predictive_new_train_tensorial_problem, predictions_explanatory_new_train_tensorial_problem = cargar_datos_y_resultados(\"tensorial_problem\")\n",
    "train_total_loss_list_tensorial_problem = results_first_train_tensorial_problem['train_total_loss_list'] + results_new_train_tensorial_problem['train_total_loss_list']\n",
    "test_total_loss_list_tensorial_problem = results_first_train_tensorial_problem['test_total_loss_list'] + results_new_train_tensorial_problem['test_total_loss_list']\n",
    "train_total_MSE_list_tensorial_problem = results_first_train_tensorial_problem['train_total_MSE_list'] + results_new_train_tensorial_problem['train_total_MSE_list']\n",
    "test_total_MSE_list_tensorial_problem = results_first_train_tensorial_problem['test_total_MSE_list'] + results_new_train_tensorial_problem['test_total_MSE_list']\n",
    "\n",
    "# Training curves of nonlinear problem P3\n",
    "train_total_loss_list_nonlinear_problem_P3 = results_first_train_nonlinear_problem_P3['train_total_loss_list'] + results_new_train_nonlinear_problem_P3['train_total_loss_list']\n",
    "test_total_loss_list_nonlinear_problem_P3 = results_first_train_nonlinear_problem_P3['test_total_loss_list'] + results_new_train_nonlinear_problem_P3['test_total_loss_list']\n",
    "train_total_MSE_list_nonlinear_problem_P3 = results_first_train_nonlinear_problem_P3['train_total_MSE_list'] + results_new_train_nonlinear_problem_P3['train_total_MSE_list']\n",
    "test_total_MSE_list_nonlinear_problem_P3 = results_first_train_nonlinear_problem_P3['test_total_MSE_list'] + results_new_train_nonlinear_problem_P3['test_total_MSE_list']\n",
    "\n",
    "# Training curves of nonlinear problem P4\n",
    "train_total_loss_list_nonlinear_problem_P4 = results_first_train_nonlinear_problem_P4['train_total_loss_list'] + results_new_train_nonlinear_problem_P4['train_total_loss_list']\n",
    "test_total_loss_list_nonlinear_problem_P4 = results_first_train_nonlinear_problem_P4['test_total_loss_list'] + results_new_train_nonlinear_problem_P4['test_total_loss_list']\n",
    "train_total_MSE_list_nonlinear_problem_P4 = results_first_train_nonlinear_problem_P4['train_total_MSE_list'] + results_new_train_nonlinear_problem_P4['train_total_MSE_list']\n",
    "test_total_MSE_list_nonlinear_problem_P4 = results_first_train_nonlinear_problem_P4['test_total_MSE_list'] + results_new_train_nonlinear_problem_P4['test_total_MSE_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step will be done if data haven't been normalized when results are beeing saved after each training iteration\n",
    "N_batch = 64\n",
    "\n",
    "train_total_loss_list_heterogeneous_problem = [x / N_batch for x in train_total_loss_list_heterogeneous_problem]\n",
    "train_total_loss_list_tensorial_problem = [x / N_batch for x in train_total_loss_list_tensorial_problem]\n",
    "train_total_loss_list_nonlinear_problem_P3 = [x / N_batch for x in train_total_loss_list_nonlinear_problem_P3]\n",
    "train_total_loss_list_nonlinear_problem_P4 = [x / N_batch for x in train_total_loss_list_nonlinear_problem_P4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "plt.plot(smooth_curve(train_total_loss_list_heterogeneous_problem), label='H', color='blue', linestyle='-')\n",
    "plt.plot(smooth_curve(train_total_loss_list_tensorial_problem), label='A', color='red', linestyle='-')\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=label_fontsize)\n",
    "plt.ylabel('Loss', fontsize=label_fontsize)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend(loc='lower left', fontsize=legend_fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlim(left=1) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "plt.plot(smooth_curve(train_total_loss_list_nonlinear_problem_P3), label='NL1', color='black', linestyle='-')\n",
    "plt.plot(smooth_curve(train_total_loss_list_nonlinear_problem_P4), label='NL2', color='green', linestyle='-')\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=label_fontsize)\n",
    "plt.ylabel('Loss', fontsize=label_fontsize)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend(loc='lower left', fontsize=legend_fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlim(left=1) \n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PGNNIV_continuum_paper_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
