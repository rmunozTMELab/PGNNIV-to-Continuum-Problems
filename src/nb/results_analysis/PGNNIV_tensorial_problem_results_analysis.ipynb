{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.colors as mcolors\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter, MaxNLocator\n",
    "\n",
    "\n",
    "custom_seed = 42\n",
    "np.random.seed(custom_seed)\n",
    "tf.random.set_seed(custom_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = \"tensorial_problem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = r' '\n",
    "results_folder = rf' '\n",
    "\n",
    "print(data_folder)\n",
    "print(results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(data_folder, f'{problem}_data.pkl')\n",
    "first_training_result_path = os.path.join(results_folder, f'{problem}_first_train.pkl')\n",
    "second_training_result_path = os.path.join(results_folder, f'{problem}_new_train.pkl')\n",
    "\n",
    "print(data_path)\n",
    "print(first_training_result_path)\n",
    "print(second_training_result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open(data_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Load first training\n",
    "with open(first_training_result_path, 'rb') as f:\n",
    "    results_first_train_pkl = pickle.load(f)\n",
    "\n",
    "results_first_train = results_first_train_pkl['training']\n",
    "predictions_predictive_first_train = results_first_train_pkl['predictions_pred']\n",
    "predictions_explanatory_first_train = results_first_train_pkl['predictions_exp']\n",
    "\n",
    "# Load second training\n",
    "with open(second_training_result_path, 'rb') as f:\n",
    "    results_second_train_pkl = pickle.load(f)\n",
    "\n",
    "results_second_train = results_second_train_pkl['training']\n",
    "predictions_predictive_second_train = results_second_train_pkl['predictions_pred']\n",
    "predictions_explanatory_second_train = results_second_train_pkl['predictions_exp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = data['n_data']\n",
    "n_discretization = data['n_discretization']\n",
    "x_step_size = data['x_step_size']\n",
    "y_step_size = data['y_step_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions that are necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finite difference convolutional operator to derivate in x axis\n",
    "def Dx(f, x_step_size=x_step_size):\n",
    "    Dx = tf.constant([[-1, +1], \n",
    "                      [-1, +1]], \n",
    "                     dtype=tf.float32)/(2*x_step_size)\n",
    "\n",
    "    f_reshaped = tf.expand_dims(f[:, :, :], axis=-1)    \n",
    "    Dx = tf.expand_dims(tf.expand_dims(Dx, axis=-1), axis=-1)\n",
    "    dfdx = tf.nn.conv2d(f_reshaped, Dx, strides=[1, 1, 1, 1], padding='VALID', name='dfdx')\n",
    "    return tf.squeeze(dfdx, axis=-1)\n",
    "\n",
    "# Finite difference convolutional operator to derivate in y axis\n",
    "def Dy(f, y_step_size=y_step_size):\n",
    "    Dy = tf.constant([[+1, +1], \n",
    "                      [-1, -1]],  \n",
    "                     dtype=tf.float32)/(-2*y_step_size)\n",
    "\n",
    "    f_reshaped = tf.expand_dims(f[:, :, :], axis=-1)    \n",
    "    Dy = tf.expand_dims(tf.expand_dims(Dy, axis=-1), axis=-1)\n",
    "    dfdy = tf.nn.conv2d(f_reshaped, Dy, strides=[1, 1, 1, 1], padding='VALID', name='dfdy')\n",
    "    return tf.squeeze(dfdy, axis=-1)\n",
    "\n",
    "# Convolutional operator to do the mean between two elements of a mesh in x axis\n",
    "def Mx(f):\n",
    "    Mx = tf.constant([[+1, +1]], \n",
    "                     dtype=tf.float32)/(2)\n",
    "\n",
    "    f_reshaped = tf.expand_dims(f[:, :, :], axis=-1)    \n",
    "    Mx = tf.expand_dims(tf.expand_dims(Mx, axis=-1), axis=-1)\n",
    "    x_avg = tf.nn.conv2d(f_reshaped, Mx, strides=[1, 1, 1, 1], padding='VALID', name='Mx')\n",
    "    return tf.squeeze(x_avg, axis=-1)\n",
    "\n",
    "# Convolutional operator to do the mean between two elements of a mesh in y axis\n",
    "def My(f):\n",
    "    My = tf.constant([[+1], \n",
    "                      [+1]], \n",
    "                     dtype=tf.float32)/(2)\n",
    "\n",
    "    f_reshaped = tf.expand_dims(f[:, :, :], axis=-1)    \n",
    "    My = tf.expand_dims(tf.expand_dims(My, axis=-1), axis=-1)\n",
    "    y_avg = tf.nn.conv2d(f_reshaped, My, strides=[1, 1, 1, 1], padding='VALID', name='My')\n",
    "    return tf.squeeze(y_avg, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(data, window_size=50):\n",
    "    window = np.ones(window_size) / window_size\n",
    "    return np.convolve(data, window, mode='valid')\n",
    "\n",
    "def cm_to_in(cm):\n",
    "    return cm * 0.393701\n",
    "\n",
    "def normalize_list(lst):\n",
    "    max_value = max(lst)\n",
    "    return [x / max_value for x in lst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphics parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "linewidth = 1.5  \n",
    "title_fontsize = 14  \n",
    "label_fontsize = 14  \n",
    "legend_fontsize = 12 \n",
    "tick_fontsize = 11  \n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "posX = cm_to_in(10) # posición de la esquina inferior izquierda de la imagen en X\n",
    "posY = cm_to_in(10) # posición de la esquina inferior izquierda de la imagen en Y\n",
    "width = cm_to_in(12)  # ancho de la imagen\n",
    "height = cm_to_in(8) # alto de la imagen\n",
    "\n",
    "color = [0.1, 0, 0.8]  # triplete RGB, valores entre 0 y 1\n",
    "subplot_adjust_left = cm_to_in(0.15)\n",
    "subplot_adjust_bottom = cm_to_in(0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total_loss_list = results_first_train['train_total_loss_list'] + results_second_train['train_total_loss_list']\n",
    "test_total_loss_list = results_first_train['test_total_loss_list'] + results_second_train['test_total_loss_list']\n",
    "\n",
    "train_total_MSE_list = results_first_train['train_total_MSE_list'] + results_second_train['train_total_MSE_list']\n",
    "test_total_MSE_list = results_first_train['test_total_MSE_list'] + results_second_train['test_total_MSE_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "plt.plot(smooth_curve(train_total_loss_list), label='Total loss train', color='blue', linestyle='-')\n",
    "plt.plot(smooth_curve(test_total_loss_list), label='Total loss test', color='red', linestyle='--')\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=label_fontsize)\n",
    "plt.ylabel('Loss', fontsize=label_fontsize)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right', fontsize=legend_fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlim(left=1) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_e_loss_list = results_first_train['train_e_loss_list'] + results_second_train['train_e_loss_list']\n",
    "train_pi1_loss_list = results_first_train['train_pi1_loss_list'] + results_second_train['train_pi1_loss_list']\n",
    "train_pi2_loss_list = results_first_train['train_pi2_loss_list'] + results_second_train['train_pi2_loss_list']\n",
    "train_pi3_loss_list = results_first_train['train_pi3_loss_list'] + results_second_train['train_pi3_loss_list']\n",
    "\n",
    "test_e_loss_list = results_first_train['test_e_loss_list'] + results_second_train['test_e_loss_list']\n",
    "test_pi1_loss_list = results_first_train['test_pi1_loss_list'] + results_second_train['test_pi1_loss_list']\n",
    "test_pi2_loss_list = results_first_train['test_pi2_loss_list'] + results_second_train['test_pi2_loss_list']\n",
    "test_pi3_loss_list = results_first_train['test_pi3_loss_list'] + results_second_train['test_pi3_loss_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "plt.plot(normalize_list(smooth_curve(train_e_loss_list)), label=r'MSE(e) ', color='red', linestyle='-')\n",
    "plt.plot(normalize_list(smooth_curve(train_pi1_loss_list)), label=r'MSE($\\pi_1$) ', color='red', linestyle='--')\n",
    "plt.plot(normalize_list(smooth_curve(train_pi2_loss_list)), label=r'MSE($\\pi_2$) ', color='red', linestyle='-.')\n",
    "plt.plot(normalize_list(smooth_curve(train_pi3_loss_list)), label=r'MSE($\\pi_3$) ', color='red', linestyle=':')\n",
    "\n",
    "plt.xlabel('Iteration', fontsize=label_fontsize)\n",
    "plt.ylabel('Normalized Loss', fontsize=label_fontsize)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right', fontsize=legend_fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "plt.xscale('log')\n",
    "plt.xlim(left=1) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_error_stats(validation, prediction, dx=x_step_size, dy=y_step_size):\n",
    "\n",
    "    prediction_error = np.sqrt((np.trapz(np.trapz((validation - prediction)**2, dx=dy), dx=dx) /\n",
    "                                np.trapz(np.trapz((validation)**2, dx=dy), dx=dx)))\n",
    "\n",
    "    min = np.min(prediction_error)\n",
    "    max = np.max(prediction_error)\n",
    "    Q1 = np.percentile(prediction_error, 25)\n",
    "    Q2 = np.percentile(prediction_error, 50)\n",
    "    Q3 = np.percentile(prediction_error, 75)\n",
    "\n",
    "    print(f\"Min: {min:.2e}\")\n",
    "    print(f\"Max: {max:.2e}\")\n",
    "    print(f\"First quartile (Q1): {Q1:.2e}\")\n",
    "    print(f\"Second quartile (Q2): {Q2:.2e}\")\n",
    "    print(f\"Third quartile (Q3): {Q3:.2e}\")\n",
    "\n",
    "def absolute_error_stats(validation, prediction, dx=x_step_size, dy=y_step_size):\n",
    "    prediction_error = np.sqrt(np.trapz(np.trapz((validation - prediction)**2, dx=dy), dx=dx))\n",
    "\n",
    "    min = np.min(prediction_error)\n",
    "    max = np.max(prediction_error)\n",
    "    Q1 = np.percentile(prediction_error, 25)\n",
    "    Q2 = np.percentile(prediction_error, 50)\n",
    "    Q3 = np.percentile(prediction_error, 75)\n",
    "\n",
    "    print(f\"Min: {min:.2e}\")\n",
    "    print(f\"Max: {max:.2e}\")\n",
    "    print(f\"First quartile (Q1): {Q1:.2e}\")\n",
    "    print(f\"Second quartile (Q2): {Q2:.2e}\")\n",
    "    print(f\"Third quartile (Q3): {Q3:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution $u(x, y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_solution = data['y_val']\n",
    "predicted_solution = predictions_predictive_second_train\n",
    "solution_diff = np.mean(np.abs(predicted_solution - validation_solution), axis=0)\n",
    "\n",
    "relative_error_stats(validation=validation_solution, prediction=predicted_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(height*1.2, height))\n",
    "\n",
    "# Plot of the image\n",
    "plt.imshow(solution_diff, interpolation='bicubic', extent=[0, 1, 0, 1])\n",
    "\n",
    "# Colorbar and axis configuration\n",
    "cbar = plt.colorbar(fraction=0.046, pad=0.04)\n",
    "cbar.formatter = ScalarFormatter(useMathText=True)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "cbar.update_ticks()\n",
    "ticks = cbar.get_ticks()\n",
    "new_ticks = (ticks + ticks[1]/10)\n",
    "cbar.set_ticks(new_ticks[1:-1])\n",
    "\n",
    "# Other parameters\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diffusivity $K(x, y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_K = My(Mx(tf.convert_to_tensor(data['k_val'], dtype=tf.float32)))\n",
    "predicted_K = predictions_explanatory_second_train\n",
    "\n",
    "Kxx_val = validation_K[0, 0, :, :].numpy()  \n",
    "Kxy_val = validation_K[0, 1, :, :].numpy()\n",
    "Kyy_val = validation_K[0, 3, :, :].numpy()\n",
    "\n",
    "Kxx_pred = predicted_K[0, :, :]\n",
    "Kxy_pred = predicted_K[1, :, :]\n",
    "Kyy_pred = predicted_K[3, :, :]\n",
    "\n",
    "Kxx_diff = np.abs(Kxx_pred - Kxx_val)\n",
    "Kxy_diff = np.abs(Kxy_pred - Kxy_val)\n",
    "Kyy_diff = np.abs(Kyy_pred - Kyy_val)\n",
    "\n",
    "relative_error_stats(validation=validation_K, prediction=predicted_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_error_K_tensorial(validation, prediction):\n",
    "\n",
    "    expanded_prediction = tf.tile(tf.expand_dims(prediction, axis=0), tf.constant([2000, 1, 1, 1]))\n",
    "\n",
    "    numerator = np.trapz(np.trapz((validation[:, 0] - expanded_prediction[:, 0])**2)) + np.trapz(np.trapz((validation[:, 1] - expanded_prediction[:, 1])**2)) + np.trapz(np.trapz((validation[:, 2] - expanded_prediction[:, 2])**2)) + np.trapz(np.trapz((validation[:, 3] - expanded_prediction[:, 3])**2))\n",
    "    denominator = np.trapz(np.trapz((validation[:, 0])**2)) + np.trapz(np.trapz((validation[:, 1])**2)) + np.trapz(np.trapz((validation[:, 2])**2)) + np.trapz(np.trapz((validation[:, 3])**2))\n",
    "    prediction_error = np.sqrt(numerator/denominator)\n",
    "\n",
    "    min = np.min(prediction_error)\n",
    "    max = np.max(prediction_error)\n",
    "    Q1 = np.percentile(prediction_error, 25)\n",
    "    Q2 = np.percentile(prediction_error, 50)\n",
    "    Q3 = np.percentile(prediction_error, 75)\n",
    "\n",
    "    print(f\"Min: {min:.2e}\")\n",
    "    print(f\"Max: {max:.2e}\")\n",
    "    print(f\"First quartile (Q1): {Q1:.2e}\")\n",
    "    print(f\"Second quartile (Q2): {Q2:.2e}\")\n",
    "    print(f\"Third quartile (Q3): {Q3:.2e}\")\n",
    "\n",
    "relative_error_K_tensorial(validation=validation_K, prediction=predicted_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(height*1.2, height))\n",
    "\n",
    "# Plot of the image\n",
    "plt.imshow(Kxx_diff, interpolation='bicubic', extent=[0, 1, 0, 1])\n",
    "\n",
    "# Colorbar and axis configuration\n",
    "cbar = plt.colorbar(fraction=0.046, pad=0.04)\n",
    "cbar.formatter = ScalarFormatter(useMathText=True)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "cbar.update_ticks()\n",
    "ticks = cbar.get_ticks()\n",
    "new_ticks = (ticks + 0.005)\n",
    "cbar.set_ticks(new_ticks[0:-1])\n",
    "\n",
    "# Other parameters\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(height*1.2, height))\n",
    "\n",
    "# Plot of the image\n",
    "plt.imshow(Kxy_diff, interpolation='bicubic', extent=[0, 1, 0, 1])\n",
    "\n",
    "# Colorbar and axis configuration\n",
    "cbar = plt.colorbar(fraction=0.046, pad=0.04)\n",
    "cbar.formatter = ScalarFormatter(useMathText=True)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "cbar.update_ticks()\n",
    "ticks = cbar.get_ticks()\n",
    "new_ticks = (ticks + 0.005)\n",
    "cbar.set_ticks(new_ticks[0:-1])\n",
    "\n",
    "# Other parameters\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(height*1.2, height))\n",
    "\n",
    "# Plot of the image\n",
    "plt.imshow(Kyy_diff, interpolation='bicubic', extent=[0, 1, 0, 1])\n",
    "\n",
    "# Colorbar and axis configuration\n",
    "cbar = plt.colorbar(fraction=0.046, pad=0.04)\n",
    "cbar.formatter = ScalarFormatter(useMathText=True)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "cbar.update_ticks()\n",
    "ticks = cbar.get_ticks()\n",
    "new_ticks = (ticks + 0.005)\n",
    "cbar.set_ticks(new_ticks[0:-1])\n",
    "\n",
    "# Other parameters\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flux $q_x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_qx = My(Mx(tf.convert_to_tensor(data['qx_val'], dtype=tf.float32)))\n",
    "predicted_qx = predicted_K[0]*Dx(predictions_predictive_second_train).numpy() + predicted_K[1]*Dx(predictions_predictive_second_train).numpy()\n",
    "qx_diff = np.mean(np.abs(predicted_qx - validation_qx), axis=0)\n",
    "\n",
    "relative_error_stats(validation=validation_qx, prediction=predicted_qx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(height*1.2, height))\n",
    "\n",
    "# Plot of the image\n",
    "plt.imshow(qx_diff, interpolation='bicubic', extent=[0, 1, 0, 1])\n",
    "\n",
    "# Colorbar and axis configuration\n",
    "cbar = plt.colorbar(fraction=0.046, pad=0.04)\n",
    "cbar.formatter = ScalarFormatter(useMathText=True)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "cbar.update_ticks()\n",
    "ticks = cbar.get_ticks()\n",
    "new_ticks = (ticks + 0.005)\n",
    "cbar.set_ticks(new_ticks[1:-1])\n",
    "\n",
    "# Other parameters\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flux $q_y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_qy = My(Mx(tf.convert_to_tensor(data['qy_val'], dtype=tf.float32)))\n",
    "predicted_qy = predicted_K[2]*Dy(predictions_predictive_second_train).numpy() + predicted_K[3]*Dy(predictions_predictive_second_train).numpy()\n",
    "qy_diff = np.mean(np.abs(predicted_qy - validation_qy), axis=0)\n",
    "\n",
    "relative_error_stats(validation=validation_qy, prediction=predicted_qy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(height*1.2, height))\n",
    "\n",
    "# Plot of the image\n",
    "plt.imshow(qy_diff, interpolation='bicubic', extent=[0, 1, 0, 1])\n",
    "\n",
    "# Colorbar and axis configuration\n",
    "cbar = plt.colorbar(fraction=0.046, pad=0.04)\n",
    "cbar.formatter = ScalarFormatter(useMathText=True)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "cbar.update_ticks()\n",
    "ticks = cbar.get_ticks()\n",
    "new_ticks = (ticks + 0.005)\n",
    "cbar.set_ticks(new_ticks[1:-1])\n",
    "\n",
    "# Other parameters\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_K = validation_K.numpy()\n",
    "val_K = val_K.transpose(0, 2, 3, 1).reshape(validation_K.shape[0], *validation_K.shape[-2:], 2, 2)\n",
    "eigenvalues_val, eigenvectors_val = np.linalg.eig(val_K)\n",
    "\n",
    "pred_K = predicted_K\n",
    "pred_K = pred_K.transpose(1, 2, 0).reshape(*validation_K.shape[-2:], 2, 2)\n",
    "eigenvalues_pred, eigenvectors_pred = np.linalg.eig(pred_K)\n",
    "\n",
    "Dx_val = eigenvectors_val[0, :, :, 0, 0]\n",
    "Dy_val = eigenvectors_val[0, :, :, 1, 0]\n",
    "\n",
    "Dx_pred = eigenvectors_pred[:, :, 0, 0]\n",
    "Dy_pred = eigenvectors_pred[:, :, 1, 0]\n",
    "\n",
    "angles_val = np.arctan2(Dy_val, Dx_val)\n",
    "angles_pred = np.arctan2(Dy_pred, Dx_pred)\n",
    "angle_diff = angles_pred - angles_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, validation_K.shape[-2])\n",
    "y = np.linspace(0, 1, validation_K.shape[-1])\n",
    "\n",
    "plt.figure(figsize=(height, height))\n",
    "\n",
    "# Plot of the quiverplots\n",
    "plt.quiver(x, y, Dx_val, Dy_val, color='black', label=r'Validation')\n",
    "plt.quiver(x, y, Dx_pred, Dy_pred, color='red', label=r'Prediction')\n",
    "\n",
    "# Axis configuration and other parameters\n",
    "plt.xlabel('$x$', fontsize=label_fontsize)\n",
    "plt.ylabel('$y$', fontsize=label_fontsize)\n",
    "plt.xticks(np.arange(0, 1.1, 0.2), fontsize=tick_fontsize)\n",
    "plt.yticks(np.arange(0, 1.1, 0.2), fontsize=tick_fontsize)\n",
    "plt.legend(loc='upper right', fontsize=legend_fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "\n",
    "# Show the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(height*1.2, height))\n",
    "\n",
    "# Plot of the image\n",
    "plt.imshow(np.flipud(np.abs(angle_diff)), interpolation='bicubic', vmin=0, vmax=np.pi, extent=[0, 1, 0, 1])\n",
    "\n",
    "# Colorbar and axis configuration\n",
    "cbar = plt.colorbar(fraction=0.046, pad=0.04)\n",
    "cbar.formatter = ScalarFormatter(useMathText=True)\n",
    "cbar.formatter.set_powerlimits((0, 0))\n",
    "cbar.update_ticks()\n",
    "ticks = cbar.get_ticks()\n",
    "new_ticks = (ticks + 0.05)\n",
    "cbar.set_ticks(new_ticks[0:-1])\n",
    "\n",
    "# Other parameters\n",
    "plt.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(validation_data, predicted_data):\n",
    "    numerator = np.trapz(np.trapz((validation_data - predicted_data)**2))\n",
    "    denominator = np.trapz(np.trapz((validation_data)**2))\n",
    "\n",
    "    if np.all(denominator == 0):\n",
    "        result = np.sqrt(numerator)\n",
    "    else:\n",
    "        result = np.sqrt(numerator / denominator)\n",
    "    return result\n",
    "\n",
    "def relative_error(validation, prediction):\n",
    "    return (np.trapz(np.trapz((validation - prediction)**2))/np.trapz(np.trapz((validation)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_solution = relative_error(validation_solution, predicted_solution)\n",
    "E_qx = relative_error(validation_qx, predicted_qx)\n",
    "E_qy = relative_error(validation_qy, predicted_qy)\n",
    "\n",
    "a = data['a_val']\n",
    "b = data['b_val']\n",
    "c = data['c_val']\n",
    "\n",
    "def plot_error(a, b, c, error, variable):\n",
    "    \n",
    "    print(variable)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    sc = ax.scatter(a, b, c, c=error, cmap='viridis', s=15, alpha=0.8, norm=mcolors.LogNorm())\n",
    "    cbar = plt.colorbar(sc, pad=0.12, shrink=0.9)\n",
    "    cbar.set_label('$E_r$')\n",
    "\n",
    "    ax.set_xlabel('$a$')\n",
    "    ax.set_ylabel('$b$')\n",
    "    ax.set_zlabel('$c$')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_error(a=a, b=b, c=c, error=E_solution, variable='solution')\n",
    "plot_error(a=a, b=b, c=c, error=E_qx, variable='qx')\n",
    "plot_error(a=a, b=b, c=c, error=E_qy, variable='qy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tests_enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
